{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 43801,
     "status": "ok",
     "timestamp": 1759463765798,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "442KkgEguNnE"
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install transformers datasets torch pandas scikit-learn accelerate -q\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680,
     "referenced_widgets": [
      "5721127bc77f4aa98598d943c85a1b33",
      "2989c5f95fd0486f9177fac265bcd49b",
      "e2a8135188c0480090f6d22b1f0100fc",
      "ba4fd26acccc4b8685ac890639ce546c",
      "04b761cc18834a078a7692b72e38cce6",
      "96ec7bd468254f56969fcbbdcdb96808",
      "25b71390049c4e6d90f2fcdb0c87c284",
      "82a7be6026974fd7ac03357f72c48865",
      "0b337d63a71b41ba83e932ec46cd070c",
      "38921322aeae4e2abde2d47aa1ab7ace",
      "7c508c2ce7a94d8ab01a622c039e7bbf",
      "e465b4a6c2004f65a435de9a78fa1b35",
      "16e33d90fea24436a0110bfbfab70561",
      "b5e7da9843224b8a8774a7e14d772195",
      "263d235c16244c41964195ea5251a023",
      "1cd03b7e00c342a19146e04e8d27f919",
      "414255f808cc4e8496134ceac866e233",
      "6f6ca46f8b2d4455a0c421e9f2844136",
      "0b36616bff1e48d78e3fb29a21f448a8",
      "fdba2706acb54f5c8db556da2267f250",
      "9aa4e58dc4364e00ac9974c0bd7e57e9",
      "7acfced766274873b3b0eb9d4dccc628",
      "31aa885926c94a1682644b214d2b23f6",
      "cb51828c07f044c8822a986b227fec28",
      "9a0ff739017a44a88c24d4a54120af0d",
      "715a0bb98e9c4906bcecd6213f5f37d8",
      "9d70f6423cde4032a011c905b23dc596",
      "e97d74f860724783ac4869c4f1e10dc9",
      "9af9ae48df1549ddb8ad8be90315e712",
      "065f5177c53243b8be14ac397f075c11",
      "db48fe9be129454c8ef8d5996c1ab356",
      "dbfcc0011d65440c9e9949ce6f684806",
      "22d55b4924774633aef7c92a17bed29b",
      "412153097e6048ddb0be0c2e4dc4ffbf",
      "20dbc16a80594b12bbe492434617962b",
      "96ed69daf2754ae396b281ec8ce4d69b",
      "4515876603a94fd5a816ddde2228da50",
      "acf930a0a9c04f219cae41e6d98557a9",
      "6b01b8a0d49d4150af7e106a8e2cf695",
      "a52aa181eb3649bdacbd490c1940088d",
      "f5d7bb27f7dc40ad8e3675f0983c300e",
      "f42afa98cc134f53b1385c5d15ce5dd5",
      "494b938a87844be1baa79629a2d11cfb",
      "d62f93acbeeb4d7cbf31e6451bf4704b",
      "6c84c6489c5848aaaf9b964df9526699",
      "c687aaa4ae794b8ab60a5182ddd8f864",
      "e0b7acb9e14e4230beee941f56f6a2ca",
      "225f0fe73d7a4ba182f2b4c507631053",
      "1a36337d0cd746bcb1fccfc2ee76093d",
      "4d3d067b21884296ba627e57b9dce0ed",
      "bb7d3ce49ad04c6aa12c90efee9e57e2",
      "54b74bbe2e554003b7ef4c7b5a6a8adb",
      "1389cf0cdeed4e7fa4e1a8e92b22ab70",
      "116e8e2009b44f059b6ae4a7ad27d9ae",
      "726ad7b737c34ee89cda32be14811ce3"
     ]
    },
    "executionInfo": {
     "elapsed": 17382,
     "status": "ok",
     "timestamp": 1759463783188,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "bkq-H2HDuQIe",
    "outputId": "7ad7f405-a055-4353-ab61-6904feceb34c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns: Index(['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID',\n",
      "       'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime'],\n",
      "      dtype='object')\n",
      "\n",
      "Sample from the training data:\n",
      "   Sr No.                                          Utterance          Speaker  \\\n",
      "0       1  also I was the point person on my company’s tr...         Chandler   \n",
      "1       2                   You must’ve had your hands full.  The Interviewer   \n",
      "2       3                            That I did. That I did.         Chandler   \n",
      "3       4      So let’s talk a little bit about your duties.  The Interviewer   \n",
      "4       5                             My duties?  All right.         Chandler   \n",
      "\n",
      "    Emotion Sentiment  Dialogue_ID  Utterance_ID  Season  Episode  \\\n",
      "0   neutral   neutral            0             0       8       21   \n",
      "1   neutral   neutral            0             1       8       21   \n",
      "2   neutral   neutral            0             2       8       21   \n",
      "3   neutral   neutral            0             3       8       21   \n",
      "4  surprise  positive            0             4       8       21   \n",
      "\n",
      "      StartTime       EndTime  \n",
      "0  00:16:16,059  00:16:21,731  \n",
      "1  00:16:21,940  00:16:23,442  \n",
      "2  00:16:23,442  00:16:26,389  \n",
      "3  00:16:26,820  00:16:29,572  \n",
      "4  00:16:34,452  00:16:40,917  \n",
      "\n",
      "Emotion to ID Mapping: {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger': 6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5721127bc77f4aa98598d943c85a1b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e465b4a6c2004f65a435de9a78fa1b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31aa885926c94a1682644b214d2b23f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412153097e6048ddb0be0c2e4dc4ffbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c84c6489c5848aaaf9b964df9526699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_url = 'https://raw.githubusercontent.com/declare-lab/MELD/master/data/MELD/train_sent_emo.csv'\n",
    "dev_url = 'https://raw.githubusercontent.com/declare-lab/MELD/master/data/MELD/dev_sent_emo.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_url)\n",
    "df_dev = pd.read_csv(dev_url)\n",
    "\n",
    "print(\"Dataset columns:\", df_train.columns)\n",
    "print(\"\\nSample from the training data:\")\n",
    "print(df_train.head())\n",
    "\n",
    "emotion_labels = df_train['Emotion'].unique()\n",
    "label2id = {label: i for i, label in enumerate(emotion_labels)}\n",
    "id2label = {i: label for i, label in enumerate(emotion_labels)}\n",
    "\n",
    "print(\"\\nEmotion to ID Mapping:\", label2id)\n",
    "\n",
    "df_train['label'] = df_train['Emotion'].map(label2id)\n",
    "df_dev['label'] = df_dev['Emotion'].map(label2id)\n",
    "\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(emotion_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1759463783406,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "qnRTX-O3uaiJ",
    "outputId": "e4ae93a8-1d58-4d80-e84c-e3e48e191c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sentence: 'Why do all you guys have to be so goofy?'\n",
      "Actual emotion: anger\n",
      "------------------------------\n",
      "PREDICTION BEFORE TRAINING:\n",
      "Predicted emotion: disgust\n",
      "\n",
      "NOTE: The prediction is random because the model's classification head has not been trained yet.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_example = \"Why do all you guys have to be so goofy?\"\n",
    "actual_emotion = \"anger\"\n",
    "\n",
    "print(f\"Example sentence: '{text_example}'\")\n",
    "print(f\"Actual emotion: {actual_emotion}\")\n",
    "print(\"-\" * 30)\n",
    "print(\"PREDICTION BEFORE TRAINING:\")\n",
    "\n",
    "inputs = tokenizer(text_example, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_id = torch.argmax(logits, dim=1).item()\n",
    "predicted_emotion = model.config.id2label[predicted_id]\n",
    "\n",
    "print(f\"Predicted emotion: {predicted_emotion}\")\n",
    "print(\"\\nNOTE: The prediction is random because the model's classification head has not been trained yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "referenced_widgets": [
      "93b55b7317b1414ea196c02b0fee727b",
      "0c4910c9deb6480c893b2cd3508cc773",
      "dc00495781574278b7fb8a0728159734",
      "0064cd6d5e7c422fa485d81424dff1ce",
      "3ef06f8a03c0461683af8ea606cb3ed3",
      "df4e9f2423214aa48a4efdc94265f8c1",
      "786d706fc3de43768993d6ff6b4d7d6d",
      "33dd5348f1db41b3a7048f2ac7891f65",
      "2e7e0bb13f70415895e88afe0da45ca3",
      "c0f75f656fa14940ae12ee9f4d04b343",
      "64e599dbad38470fbca4b1201e073926",
      "f90f625550af495d83670c1b4151bce9",
      "5b5b1f99503047c19feca5b0e49019d0",
      "ecbbe0a1846941d18ab14c44b8d99a05",
      "2b92ec9aac564fd199c03535bee94129",
      "b28d6af08d0a4b2fbbde30ab9e697b10",
      "833232608d2a4437852e7fb58bd2dc8e",
      "1d03185d4ebf4058aef0544e0fdfc1b5",
      "5ebf0f7e4cbb4ea4b3c2ce86da63deb6",
      "f5661016706648078751f9dde6f8d246",
      "08969efdf92749059d47d443d2c45e12",
      "3460fe8ebb4e4d3f92eb86e7b389f28e"
     ]
    },
    "executionInfo": {
     "elapsed": 501873,
     "status": "ok",
     "timestamp": 1759464285284,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "IE6_UgBNuckm",
    "outputId": "ead01e3b-eeb1-42eb-c79d-01ac46238a5e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b55b7317b1414ea196c02b0fee727b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90f625550af495d83670c1b4151bce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1109 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2968187118.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for the model BEFORE training:\n",
      "{'test_loss': 1.9525814056396484, 'test_model_preparation_time': 0.0019, 'test_accuracy': 0.056807935076645624, 'test_f1': 0.033428377618716816, 'test_runtime': 16.9036, 'test_samples_per_second': 65.607, 'test_steps_per_second': 4.141}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 07:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.341200</td>\n",
       "      <td>1.226587</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.611362</td>\n",
       "      <td>0.570095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "dev_dataset = Dataset.from_pandas(df_dev)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['Utterance'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dev_dataset = dev_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'f1': f1_score(labels, predictions, average='weighted')\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    save_steps=500 # Add save_steps to save the model during training\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_dev_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "before_train_results = trainer.predict(tokenized_dev_dataset)\n",
    "\n",
    "print(\"\\nMetrics for the model BEFORE training:\")\n",
    "print(before_train_results.metrics)\n",
    "\n",
    "trainer.train()\n",
    "print(\"Fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1759464415191,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "q2gGuvItugOh",
    "outputId": "4a9e6b85-af1a-4d68-d968-467e61b392ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: I cannot believe you did this, I am so mad!\n",
      "\n",
      "Base model prediction (before training): neutral\n",
      "Probabilities: [0.16723748 0.12003696 0.14285499 0.1530111  0.14109965 0.15068448\n",
      " 0.12507531]\n",
      "\n",
      "Fine-tuned model prediction (after training): anger\n",
      "Probabilities: [0.06713898 0.08070379 0.03415503 0.12761983 0.22214466 0.08902798\n",
      " 0.37920976]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model_name,\n",
    "    num_labels=len(emotion_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "# Load the fine-tuned model from the saved path\n",
    "fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(\"./results/checkpoint-500\").to(device)\n",
    "\n",
    "\n",
    "def predict_emotion(text, model, tokenizer):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        pred_id = torch.argmax(probs, dim=1).item()\n",
    "        pred_label = model.config.id2label[pred_id]\n",
    "    return pred_label, probs.squeeze().cpu().numpy()\n",
    "\n",
    "text = \"I cannot believe you did this, I am so mad!\"\n",
    "base_label, base_probs = predict_emotion(text, base_model, tokenizer)\n",
    "ft_label, ft_probs = predict_emotion(text, fine_tuned_model, tokenizer)\n",
    "\n",
    "print(\"Input text:\", text)\n",
    "print(\"\\nBase model prediction (before training):\", base_label)\n",
    "print(\"Probabilities:\", base_probs)\n",
    "\n",
    "print(\"\\nFine-tuned model prediction (after training):\", ft_label)\n",
    "print(\"Probabilities:\", ft_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNWnrdutRWO2",
    "outputId": "438c728d-7e31-418b-cdf5-355e3779379b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat) (4.25.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat) (5.8.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbformat) (5.7.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat) (0.27.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nbformat\n",
    "\n",
    "import nbformat\n",
    "from google.colab import _message\n",
    "\n",
    "# Get the current notebook content from Colab\n",
    "nb_str = _message.blocking_request('get_ipynb')['ipynb']\n",
    "\n",
    "# Load notebook as nbformat object\n",
    "nb = nbformat.from_dict(nb_str)\n",
    "\n",
    "# Remove bad widget metadata if it exists\n",
    "if \"widgets\" in nb[\"metadata\"]:\n",
    "    nb[\"metadata\"].pop(\"widgets\")\n",
    "\n",
    "# Save a clean copy\n",
    "clean_filename = \"prototype_meld_clean.ipynb\"\n",
    "with open(clean_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    nbformat.write(nb, f)\n",
    "\n",
    "print(f\"✅ Cleaned and saved as {clean_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
